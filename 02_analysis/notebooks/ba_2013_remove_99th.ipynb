{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T14:43:50.237476Z",
     "start_time": "2019-05-07T14:43:50.226794Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point, Polygon, shape\n",
    "import geopandas as gpd\n",
    "import pickle\n",
    "\n",
    "# Import custom functions from `scripts` folder\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from scripts.clean_tweets import geometrize_tweets, convert_shapefile_crs, find_frequencies\n",
    "from scripts.home_location import assign_home_location\n",
    "\n",
    "np.random.seed(42)\n",
    "pd.set_option('display.max_columns', 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-04T01:31:02.583307Z",
     "start_time": "2019-05-04T01:29:50.113997Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/public/jsp/twitter-and-displacement/.env/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "ba13 = pd.read_csv('../data/tweets/ba_2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T15:00:51.022566Z",
     "start_time": "2019-05-07T14:59:21.310927Z"
    }
   },
   "outputs": [],
   "source": [
    "ba_shapefiles = gpd.read_file('../data/shapefiles/buenos_aires_shapefiles/BA_2010.shp')\n",
    "ba_shapefiles = convert_shapefile_crs(ba_shapefiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering data and adding tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-04T01:32:38.877213Z",
     "start_time": "2019-05-04T01:32:37.930537Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute summary stats\n",
    "num_tweets_13, num_users_13, median_tweets_13 = len(ba13), ba13['u_id'].nunique(), ba13.groupby('u_id').size().median()\n",
    "percentile_99 = ba13.groupby('u_id').size().quantile(.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-04T01:34:04.185393Z",
     "start_time": "2019-05-04T01:32:38.878901Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter based on median tweets for 2013\n",
    "ba13_filtered = ba13.groupby('u_id').filter(lambda group: (len(group) >= median_tweets_13) & (len(group) <= percentile_99) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-04T01:36:14.747475Z",
     "start_time": "2019-05-04T01:34:04.187647Z"
    }
   },
   "outputs": [],
   "source": [
    "# Geometrize tweets based on lat/lon\n",
    "ba13_filtered = geometrize_tweets(ba13_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-04T01:36:20.487560Z",
     "start_time": "2019-05-04T01:36:14.749417Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add datetime\n",
    "ba13_filtered['timestamp'] = pd.to_datetime(ba13_filtered['created_at'] // 1000, unit='s')\n",
    "ba13_filtered['date'] = ba13_filtered['timestamp'].dt.date\n",
    "ba13_filtered['hour'] = ba13_filtered['timestamp'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-04T01:55:52.374875Z",
     "start_time": "2019-05-04T01:36:20.490802Z"
    }
   },
   "outputs": [],
   "source": [
    "# Spatial join for tracts; add home locations\n",
    "ba13_filtered = gpd.sjoin(ba13_filtered, ba_shapefiles, how='left', op='intersects')\n",
    "ba13_filtered['home'] = assign_home_location(ba13_filtered, tract='codigo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T20:29:16.494395Z",
     "start_time": "2019-05-06T20:26:23.871465Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save data for easy loading in future\n",
    "# with open('../data/ba13_home.pkl', 'wb') as file:\n",
    "#     pickle.dump(ba13_filtered, file, protocol=4)\n",
    "with open('../data/ba13_home.pkl', 'rb') as file:\n",
    "    ba13_filtered = pickle.load(file)\n",
    "        \n",
    "ba13_filtered['is_home'] = ba13_filtered['home'] == ba13_filtered['codigo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T20:50:37.717830Z",
     "start_time": "2019-05-06T20:50:37.398183Z"
    }
   },
   "outputs": [],
   "source": [
    "# How many of the filtered tweets have a home assignment?\n",
    "print((~ba13_filtered['home'].isnull()).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T20:57:57.288875Z",
     "start_time": "2019-05-06T20:51:02.228674Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ratio of users that have home location\n",
    "ba13_filtered.groupby(['u_id']).first()['is_home'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T20:57:57.530440Z",
     "start_time": "2019-05-06T20:57:57.291069Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ratio of filtered 2013 tweets in which tweet was made from home tract \n",
    "ba13_filtered['is_home'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T21:00:52.357353Z",
     "start_time": "2019-05-06T21:00:37.385395Z"
    }
   },
   "outputs": [],
   "source": [
    "### Plot 1% of 2013 tweets\n",
    "# Blue tweets: Resident\n",
    "# Red tweets: Non-resident\n",
    "# Gray (barely visible beneath the blue): Buenos Aires shapefile\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "ba_shapefiles['geometry'].plot(ax=ax, color='gray')\n",
    "smpl = ba13_filtered.sample(frac=0.01, random_state=42)\n",
    "smpl[~smpl['is_home']].plot(ax=ax, marker='o', color='red', alpha=0.01, label='Red: Non-Resident')\n",
    "smpl[smpl['is_home']].plot(ax=ax, marker='o', color='blue', alpha=0.01, label='Blue: Resident')\n",
    "plt.legend()\n",
    "plt.axis([-58.6, -58.3, -34.75, -34.5])\n",
    "plt.title('Buenos Aires tweets, 2013');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T14:53:32.316076Z",
     "start_time": "2019-05-07T14:44:52.478869Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save data for easy loading in future\n",
    "# with open('../data/ba13_home.pkl', 'wb') as file:\n",
    "#     pickle.dump(ba13_filtered, file, protocol=4)\n",
    "with open('../data/ba13_home.pkl', 'rb') as file:\n",
    "    ba13_filtered = pickle.load(file)\n",
    "\n",
    "ba13_filtered['home'] = assign_home_location(ba13_filtered, tract='codigo')\n",
    "ba13_filtered['is_home'] = ba13_filtered['home'] == ba13_filtered['codigo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T14:53:32.622556Z",
     "start_time": "2019-05-07T14:53:32.318285Z"
    }
   },
   "outputs": [],
   "source": [
    "# How many of the filtered tweets have a home assignment?\n",
    "print((~ba13_filtered.loc[~ba13_filtered['codigo'].isnull(), 'home'].isnull()).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T14:55:51.703940Z",
     "start_time": "2019-05-07T14:53:32.624352Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ratio of users that have home location\n",
    "ba13_filtered[~ba13_filtered['codigo'].isnull()].groupby(['u_id']).first()['is_home'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T14:55:52.030929Z",
     "start_time": "2019-05-07T14:55:51.706045Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ratio of filtered 2013 tweets in which tweet was made from home tract \n",
    "ba13_filtered.loc[~ba13_filtered['codigo'].isnull(), 'is_home'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T15:01:01.078791Z",
     "start_time": "2019-05-07T15:00:51.026577Z"
    }
   },
   "outputs": [],
   "source": [
    "### Plot 1% of 2013 tweets\n",
    "# Blue tweets: Resident\n",
    "# Red tweets: Non-resident\n",
    "# Gray (barely visible beneath the blue): Buenos Aires shapefile\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "ba_shapefiles['geometry'].plot(ax=ax, color='gray')\n",
    "smpl = ba13_filtered[~ba13_filtered['codigo'].isnull()].sample(frac=0.01, random_state=42)\n",
    "smpl[~smpl['is_home']].plot(ax=ax, marker='o', color='red', alpha=0.01, label='Red: Non-Resident')\n",
    "smpl[smpl['is_home']].plot(ax=ax, marker='o', color='blue', alpha=0.01, label='Blue: Resident')\n",
    "plt.legend()\n",
    "plt.axis([-58.6, -58.3, -34.75, -34.5])\n",
    "plt.title('Buenos Aires tweets, 2013');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T04:30:01.077393Z",
     "start_time": "2019-05-08T04:29:56.084108Z"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    ba13_filtered\n",
    "    .loc[:, ['codigo', 'is_home']]\n",
    "    .groupby('codigo')\n",
    "    .agg([len, np.mean])\n",
    "    .rename(columns={'len':'count', 'mean':'home_tweet_ratio'})\n",
    ").to_csv('../data/ba13_home_by_codigo.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
