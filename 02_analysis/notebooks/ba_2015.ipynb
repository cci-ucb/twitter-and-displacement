{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T02:45:17.975802Z",
     "start_time": "2019-06-10T02:45:04.659054Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point, Polygon, shape\n",
    "import geopandas as gpd\n",
    "import pickle\n",
    "\n",
    "# Import custom functions from `scripts` folder\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from scripts.clean_tweets import geometrize_tweets, convert_shapefile_crs, find_frequencies\n",
    "from scripts.home_location import assign_home_location\n",
    "from scripts.analyze_buenos_aires import summary_stats, filter_and_home_assign\n",
    "\n",
    "np.random.seed(42)\n",
    "pd.set_option('display.max_columns', 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data\n",
    "\n",
    "(If you have access to the pickled data files, begin running cells at the cell that reads `### PICKLE FILE ###`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T02:46:45.551247Z",
     "start_time": "2019-06-10T02:45:17.978292Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading 2015 tweets\n",
    "ba15 = pd.read_csv('../data/tweets/ba_2015.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T02:48:21.801552Z",
     "start_time": "2019-06-10T02:46:45.554065Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading shapefiles\n",
    "ba_shapefiles = convert_shapefile_crs(\n",
    "    gpd.read_file('../data/shapefiles/buenos_aires_shapefiles/BA_2010.shp')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering data and adding tracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we want to filter the data to exclude rare Twitter users (tweet count below median number of tweets/user) and power users (tweet count above 99th percentile of tweets/user). Methodology is as follows:\n",
    "\n",
    "1. Compute 50th and 99th percentile of tweets/user\n",
    "1. Select the subset of tweets made by users falling between those bounds\n",
    "1. Geometrize tweet data by using lat/lon\n",
    "1. Compute a spatial join between tweets and the tract shapefiles\n",
    "1. Add datetime information for home location analysis\n",
    "1. Assign home locations (`home` column) and whether or not tweet is made from home (`is_home` column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-10T02:45:03.367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18962977 total tweets\n",
      "333464 unique users\n",
      "\n",
      "Median number of tweets/user: 6.0 tweets\n",
      "99th percentile of tweets/user: 866.0 tweets\n"
     ]
    }
   ],
   "source": [
    "# Original dataset analysis\n",
    "pct_50, pct_99 = summary_stats(ba15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-10T02:45:03.368Z"
    }
   },
   "outputs": [],
   "source": [
    "ba15 = filter_and_home_assign(ba15, ba_shapefiles, pct_50, pct_99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-10T02:45:03.369Z"
    }
   },
   "outputs": [],
   "source": [
    "### PICKLE FILE ###\n",
    "# protocol=4 for large data files (https://stackoverflow.com/a/56151766)\n",
    "with open('../data/ba15.pkl', 'wb') as file:\n",
    "    pickle.dump(ba15, file, protocol=4)\n",
    "\n",
    "# with open('../data/ba15.pkl', 'rb') as file:\n",
    "#     ba15 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "Before we begin our analysis, it helps to show a visual analysis of where our tweets are located. In the map below, we differentiate between the tweets that are assigned a `codigo` in our spatial join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-10T02:45:03.371Z"
    }
   },
   "outputs": [],
   "source": [
    "### Plot a 1% sample of 2015 tweets ###\n",
    "# Green tweets: Joined to a codigo\n",
    "# Orange tweets: No codigo assigned (NaN)\n",
    "# Gray (barely visible beneath the blue): Buenos Aires shapefile\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "ba_shapefiles['geometry'].plot(ax=ax, color='gray')\n",
    "sample = ba15.sample(frac=0.01, random_state=42)\n",
    "sample[~sample['codigo'].isnull()].plot(ax=ax, marker='o', color='green', alpha=0.01, label='Green: Within Metropolitan Area')\n",
    "sample[sample['codigo'].isnull()].plot(ax=ax, marker='o', color='orange', alpha=0.01, label='Orange: Outside Metropolitan Area')\n",
    "plt.legend()\n",
    "plt.axis([-58.6, -58.3, -34.75, -34.5])\n",
    "plt.title('Buenos Aires tweets, 2015: Metropolitan vs. Outside');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we see that we can use `[~ba15['codigo'].isnull()]` as a filter to select just the tweets in the metropolitan area, which is our area of interest. For all following analyses, we will restrict the population to just the tweets that fall inside the metropolitan area depicted by the shapefile.\n",
    "\n",
    "Our first summary statistic computes the ratio of tweets that have a home assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-10T02:45:03.372Z"
    }
   },
   "outputs": [],
   "source": [
    "num_home_assigned_tweets = (~ba15.loc[~ba15['codigo'].isnull(), 'home'].isnull()).sum()\n",
    "n_tweets = len(ba15[~ba15['codigo'].isnull()])\n",
    "\n",
    "print(\"{}/{} = {:.2%} of tweets have a home assignment.\".format(\n",
    "    num_home_assigned_tweets, n_tweets, num_home_assigned_tweets / n_tweets\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T00:39:40.432699Z",
     "start_time": "2019-05-25T00:39:40.426377Z"
    }
   },
   "source": [
    "Next, we are interested in the ratio of users that have a home assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-10T02:45:03.374Z"
    }
   },
   "outputs": [],
   "source": [
    "num_users_with_home = (~ba15.loc[~ba15['codigo'].isnull()].groupby('u_id')['home'].first().isnull()).sum()\n",
    "n_users = len(ba15[~ba15['codigo'].isnull()].groupby('u_id'))\n",
    "\n",
    "print(\"{}/{} = {:.2%} of users have a home assignment.\".format(\n",
    "    num_users_with_home, n_users, num_users_with_home / n_users\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we want to know the ratio of tweets that were made from home (i.e. `codigo` and `home` are equal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-10T02:45:03.375Z"
    }
   },
   "outputs": [],
   "source": [
    "num_tweets_from_home = ba15.loc[~ba15['codigo'].isnull(), 'is_home'].sum()\n",
    "\n",
    "print(\"{}/{} = {:.2%} of tweets are posted from the home tract.\".format(\n",
    "    num_tweets_from_home, n_tweets, num_tweets_from_home / n_tweets\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our analysis concludes with a visual representation of this last information; namely, how are the tweets spread out across the entire metropolitan area of Buenos Aires with respect to residence/nonresidence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-10T02:45:03.377Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Plot a 5% sample of 2015 tweets ###\n",
    "# Blue tweets: Resident\n",
    "# Red tweets: Non-resident\n",
    "# Gray (barely visible beneath the blue): Buenos Aires shapefile\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "ba_shapefiles['geometry'].plot(ax=ax, color='gray')\n",
    "sample = ba15[~ba15['codigo'].isnull()].sample(frac=0.05, random_state=42)\n",
    "sample[~sample['is_home']].plot(ax=ax, marker='o', color='red', alpha=0.01, label='Red: Non-Resident')\n",
    "sample[sample['is_home']].plot(ax=ax, marker='o', color='blue', alpha=0.01, label='Blue: Resident')\n",
    "plt.legend()\n",
    "plt.axis([-58.6, -58.3, -34.75, -34.5])\n",
    "plt.title('Buenos Aires tweets, 2015: Resident vs. Non-resident');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving output\n",
    "\n",
    "For future reference, we save two outputs:\n",
    "\n",
    "1. Number of tweets + home tweet ratio for each codigo\n",
    "1. Tweets from the following focus codigos (with some restrictions, specified in code):\n",
    "    - Parque Patricios\n",
    "    - Boca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-10T02:45:03.380Z"
    }
   },
   "outputs": [],
   "source": [
    "##### 1. Number of tweets + home tweet ratio for each codigo #####\n",
    "(\n",
    "    ba15\n",
    "    .loc[~ba15['codigo'].isnull(), ['codigo', 'is_home']]\n",
    "    .groupby('codigo')\n",
    "    .agg([len, np.mean])\n",
    "    .T.reset_index(drop=True).T\n",
    "    .rename(columns={0:'count', 1:'home_tweet_ratio'})\n",
    ").to_csv('../data/ba15_by_codigo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-10T02:45:03.382Z"
    }
   },
   "outputs": [],
   "source": [
    "##### 2. Tweets from focus codigos #####\n",
    "def save_focus_codigo_data(data, year):\n",
    "    parque = data[(data['BARRIOS'] == 'PARQUE PATRICIOS') | \n",
    "                  (data['codigo'].isin([20041001, 20012905, 20032309]))]\n",
    "    boca = data[(data['BARRIOS'] == 'BOCA') & (data['codigo'] != 20041801)]\n",
    "    \n",
    "    parque.to_csv('../data/ba' + str(year)[-2:] + '_PARQUE_PATRICIOS.csv', index=False)\n",
    "    boca.to_csv('../data/ba' + str(year)[-2:] + '_BOCA.csv', index=False)\n",
    "    \n",
    "save_focus_codigo_data(ba15, 2015)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
